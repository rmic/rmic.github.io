{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"/lost+found/","text":"<p>A stash of ideas, side quests, and near misses.</p> <p>Welcome to my stash of projects, write-ups, and experiments across software engineering, data engineering, MLOps and other various (sometimes only loosely) related topics...</p> <p>This blog is meant to share reusable stuff that I tried and that actually works (or at least that \"works on my machine \u00af_(\u30c4)_/\u00af'), the things I googled and fought with so you don't have to, the so-called \"solutions\" that chat gipitty (or g-pity ?) gave and that I struggled with and finally fixed because the stuff it generated didn't work at first.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/","title":"Why a pixel is not a geographic point","text":"<p>TL;DR</p> <p>A pixel is an image-space measurement, not a location on Earth. Treating it as a point is a category error that silently breaks geospatial reasoning.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#the-intuitive-assumption","title":"The intuitive assumption","text":"<p>If you work with images, maps, or computer vision, this assumption feels natural:</p> <p>\u201cThis object is at pixel (x, y), so I know where it is.\u201d</p> <p>A slightly more refined version often follows: \u201cI know the pixel coordinates and the GPS position of the image, so I can convert that pixel into latitude and longitude.\u201d</p> <p>This intuition is not stupid. It feels reasonable, especially if you are used to grids, arrays, coordinates and numerical precision.</p> <p>Pixels have coordinates. Maps have coordinates. So why shouldn\u2019t one turn into the other?</p> <p>Because they exist in different worlds. </p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#what-a-pixel-actually-is","title":"What a pixel actually is","text":"<p>Long story short : A pixel is not a point.</p> <p>It is a small \u2014 sometimes very small \u2014 rectangular area on a camera sensor. During an exposure, that area integrates incoming light from the scene in front of the camera. Nothing in that process encodes depth, direction, or position in the world.</p> <p>Even before talking about geography, a pixel already has extent, not location.</p> <p>A pixel in its simplest form is an area over the camera sensor.</p> <p>At this stage, nothing in the image tells you:</p> <ul> <li>where on Earth this pixel comes from</li> <li>how far or how large the observed surface is</li> <li>or in which direction the scene lies</li> </ul> <p>The pixel exists purely in image space.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#giving-pixels-a-physical-size-ground-sampling-distance","title":"Giving pixels a physical size: Ground Sampling Distance","text":"<p>To make pixels feel more concrete, practitioners often introduce Ground Sampling Distance (GSD).</p> <p>GSD answers a simple question: \"If this image were taken under ideal conditions, how much ground would one pixel roughly cover?\"</p> <p>Under strong assumptions (e.g. perfectly flat terrain, nadir view, known altitude, no lens distortion, ...) the GSD can be approximated from:</p> <ul> <li>flight altitude</li> <li>camera focal length</li> <li>physical pixel size on the sensor</li> </ul> <p>Increase altitude, and each pixel covers more ground. Change sensor or lens, and the same pixel suddenly represents a whole different surface area.</p> <p>Understanding this is useful. It immediately breaks the illusion that pixels are dimensionless. A pixel can represent centimeters, decimeters, or meters on the ground, depending on context.</p> <p>But GSD only describes scale \u2014 not location. A pixel with a known ground size can still be misplaced by meters.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#why-gsd-is-not-enough","title":"Why GSD is not enough","text":"<p>So far, we have seen that GSD tells you how much ground a pixel might roughly represent. It still says nothing about which part of the ground that pixel is actually seeing.</p> <p>To answer that question, we would need:</p> <ul> <li>a viewing direction</li> <li>a camera pose</li> <li>a reference frame</li> <li>and a model of the terrain</li> </ul> <p>Without these, GSD provides a comforting number \u2014 but no geometric truth.</p> <p>Out of scope (for now)</p> <p>GSD is often treated as constant, but in reality it varies across an image, changes with viewing angle, and breaks down completely on sloped terrain. These effects are real and important \u2014 and we will come back to them later \u2014 but they are not required to understand the core idea here:</p> <p>a pixel does not have an intrinsic position and its apparent size only exists under strong assumptions</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#the-hidden-assumptions","title":"The hidden assumptions","text":"<p>Turning a pixel into a geographic point does not fail because people are careless. It fails because it relies on a stack of assumptions that are rarely stated explicitly.</p> <p>When you click on an image, run a detection model, or export a point from imagery, you are implicitly assuming that all of the following are true \u2014 at the same time.</p> <p>A pixel corresponds to a single ray</p> <p>The first assumption is that a pixel can be reduced to a single viewing direction.</p> <p>In reality, a pixel is an area on the sensor. Light reaching that area arrives from a small cone of directions, not from a perfectly defined ray. Camera models usually collapse that cone into a single central ray because it is convenient \u2014 and often sufficient \u2014 but this is already an approximation.</p> <p>For most applications, this approximation is harmless. For precise geometry, it is the first place where uncertainty enters the system.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#that-ray-intersects-the-ground-at-a-unique-point","title":"That ray intersects the ground at a unique point","text":"<p>Once a pixel is treated as a ray, a second assumption follows naturally: that the ray intersects the ground once, at a well-defined location.</p> <p>This is only true if the surface is continuous and there are no vertical structures or occlusions.</p> <p>In real scenes, a single ray can intersect a roof edge, a fa\u00e7ade, vegetation, or the ground behind an object.</p> <p>Choosing which intersection is \u201cthe point\u201d is already a modeling decision \u2014 even if it is never exposed as such.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#the-ground-is-planar-or-at-least-predictable","title":"The ground is planar (or at least predictable)","text":"<p>Most pixel-to-ground conversions quietly assume that the ground can be approximated as flat, horizontal, or very smoothly varying.</p> <p>This assumption is often justified with phrases like \u201cthe area is small\u201d or \u201cthe terrain is simple\u201d. But small and flat does not mean level, and simple does not mean planar.</p> <p>Even gentle slopes introduce sometimes significant lateral displacement. Even minor relief breaks geometric symmetry.</p> <p>The flatter the world is assumed to be, the more confident the result appears \u2014 and the further it can quietly drift from reality.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#the-camera-pose-is-perfectly-known","title":"The camera pose is perfectly known","text":"<p>Another strong assumption is that the camera\u2019s position and orientation are known with sufficient accuracy.</p> <p>In practice, pose comes from:</p> <ul> <li>GPS / GNSS / Baidu / Galileo measurements,</li> <li>RTK adjustments,</li> <li>inertial sensors,</li> <li>time synchronization,</li> <li>calibration</li> </ul> <p>Each of these has its own uncertainty, bias, and failure modes. When pose errors exist \u2014 and they always do \u2014 they directly translate into ground position errors, often amplified by altitude and viewing angle.</p> <p>The pixel did not move. The geometry did.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#altitude-is-known-and-meaningful","title":"\u201cAltitude\u201d is known \u2014 and meaningful","text":"<p>Finally, many workflows rely on altitude as if it were a single, unambiguous value.</p> <p>But altitude relative to what?</p> <ul> <li>mean sea level (AMSL) ? Is your current ground at sea level ? </li> <li>takeoff point ? Is there always at that exact same distance between the camera sensor and the ground beneath it ? </li> <li>local terrain ?</li> <li>an ellipsoid ?</li> </ul> <p>Different definitions of altitude can differ by meters. Using the wrong one does not produce an error message \u2014 it produces a plausible but wrong result.</p> <p>This is one of the most common ways silent errors enter geospatial pipelines.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#why-this-matters","title":"Why this matters","text":"<p>None of these assumptions is absurd. Most of them are reasonable \u2014 individually.</p> <p>The problem is that they are rarely acknowledged, rarely verified, and almost never combined consciously.</p> <p>You do not make these assumptions explicitly. The tools make them for you.</p> <p>And once they are baked into a result, they are very hard to see \u2014 let alone undo.</p> <p>Understanding that these assumptions exist is the first step toward understanding why treating a pixel as a geographic point is not just imprecise, but conceptually wrong.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#from-pixel-to-ground-what-must-exist","title":"From pixel to ground: what must exist","text":"<p>To understand what it would take to turn a pixel into a geographic location, we need to be explicit about what must exist \u2014 whether we acknowledge it or not \u2014 in every pixel-to-ground conversion.</p> <p>This is not about software. It is about geometry.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#a-pixel-does-not-map-to-a-point-it-maps-to-a-question","title":"A pixel does not map to a point \u2014 it maps to a question","text":"<p>A pixel in an image corresponds to an area perceived in a viewing direction from the camera.</p> <p>That direction depends on the camera\u2019s internal geometry (sensor, lens, distortion) and the pixel\u2019s position on the sensor.</p> <p>With this information, we still do not have a location \u2014 only a direction. The moment you ask \u201cwhere is this pixel on the ground?\u201d, you are implicitly asking \u201cAlong this direction, where does the world exist?\u201d</p> <p>Answering that question requires more than an image.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#a-surface-must-be-chosen","title":"A surface must be chosen","text":"<p>To turn a viewing direction into a location, the direction must intersect something.</p> <p>That \u201csomething\u201d is a model of the world such as :</p> <ul> <li>a flat plane,</li> <li>a constant altitude,</li> <li>a digital elevation model,</li> <li>or any other representation of the terrain.</li> </ul> <p>Choosing a surface is not optional. If no surface is provided, one is assumed. This is where many workflows quietly commit to a world model without ever naming it and without the user knowing which one it is.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#intersection-is-a-decision-not-a-fact","title":"Intersection is a decision, not a fact","text":"<p>Once a surface exists, the viewing direction can be intersected with it.</p> <p>But that intersection is not a measurement \u2014 it is a result of a choice:</p> <ul> <li>which surface?</li> <li>which altitude reference?</li> <li>which resolution?</li> <li>which smoothing?</li> </ul> <p>Change the surface, and the intersection moves \u2014 sometimes by centimeters, sometimes by meters.</p> <p></p> <p>Nothing about the pixel changed. Only the assumptions did.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#reference-frames-make-locations-comparable","title":"Reference frames make locations comparable","text":"<p>Even after an intersection is computed, the result is still not a usable geographic location unless it is expressed in a reference frame.</p> <p>Coordinates only make sense relative to a reference frame, which is usually defined by three elements:</p> <ul> <li>a datum \u2014 a mathematical model of the Earth that defines what \u201czero\u201d means and how positions relate to the planet\u2019s shape (sphere, ellipsoid, reference surface).</li> <li>a projection \u2014 a rule that transforms positions on a curved surface into a flat, two\u2011dimensional space, inevitably distorting distances, angles, or areas in the process.</li> <li>a convention \u2014 a set of choices about axes, units, orientation, and coordinate order (for example: meters vs degrees, east\u2011north vs north\u2011east, origin placement).</li> </ul> <p>Different choices produce different numbers for the same physical location \u2014 all of them internally consistent, none of them universally \u201ccorrect\u201d.</p> <p>At this point, the pixel has finally become a geographic hypothesis:</p> <p>\u201cIf the world looks like this, and the camera was there, then the pixel might correspond to this location.\u201d</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#why-this-matters_1","title":"Why this matters","text":"<p>Every pixel-to-ground conversion performs these steps, explicitly or implicitly:</p> <ol> <li>derive a viewing direction</li> <li>choose a surface</li> <li>compute an intersection</li> <li>express the result in a reference frame</li> </ol> <p>When these steps are hidden, results look clean, precise, and authoritative.</p> <p>When they are exposed, it becomes clear that:</p> <ul> <li>different assumptions produce different answers,</li> <li>confidence depends on the weakest element,</li> <li>and precision without context is meaningless.</li> </ul> <p>This is not a flaw of the method. It is the nature of geometry.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#where-tools-hide-the-problem","title":"Where tools hide the problem","text":"<p>At this point, a reasonable question arises:</p> <p>If pixel-to-ground mapping relies on so many assumptions, why does it usually look fine?</p> <p>The short answer is: because tools have to decide something.</p> <p>Modern geospatial tools are not careless. They are designed to be usable, responsive, and productive. Faced with missing or ambiguous information, they do what any practical system must do: they choose sensible defaults.</p> <p>That is not a flaw. It is a necessity.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#defaults-are-answers-to-unasked-questions","title":"Defaults are answers to unasked questions","text":"<p>Every time a tool places a point on the ground from imagery, it implicitly answers questions such as:</p> <ul> <li>which surface should be used?</li> <li>which altitude reference applies?</li> <li>which projection should express the result?</li> <li>which intersection should be considered \u201cthe\u201d location?</li> </ul> <p>Most of the time, these answers are reasonable. They are chosen to work well in common situations.</p> <p>The issue is not that these defaults are wrong.</p> <p>The issue is that the questions themselves remain invisible.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#precision-hides-uncertainty","title":"Precision hides uncertainty","text":"<p>Once a choice is made, tools present the result as a clean, precise coordinate:</p> <ul> <li>a point snaps to a map</li> <li>numbers are displayed with many decimals</li> <li>layers align visually</li> </ul> <p>Nothing in the interface suggests:</p> <ul> <li>which assumptions were made</li> <li>how sensitive the result is to them</li> <li>or how much uncertainty remains</li> </ul> <p>The result looks authoritative not because it is exact, but because uncertainty has been flattened away.</p> <p>This is not deception. It is the cost of abstraction.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#abstractions-work-until-context-changes","title":"Abstractions work \u2014 until context changes","text":"<p>Defaults work remarkably well as long as the context matches the assumptions they were designed for:</p> <ul> <li>relatively flat terrain</li> <li>moderate accuracy requirements</li> <li>visual or qualitative use cases</li> </ul> <p>Problems appear when the context shifts:</p> <ul> <li>terrain relief becomes significant</li> <li>vertical accuracy matters more than horizontal alignment</li> <li>relative position is more important than absolute location</li> <li>errors accumulate across processing steps</li> </ul> <p>In those situations, the same defaults do not fail loudly. They fail quietly.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#error-budgets-when-reasonable-assumptions-accumulate","title":"Error budgets: when reasonable assumptions accumulate","text":"<p>Up to this point, none of the assumptions we have discussed is outrageous.</p> <p>Individually, they are all reasonable:</p> <ul> <li>collapsing a pixel into a single viewing direction,</li> <li>assuming a smooth or flat surface,</li> <li>trusting a camera pose estimate,</li> <li>choosing a default altitude reference,</li> <li>expressing the result in a convenient projection.</li> </ul> <p>Most systems rely on these assumptions because they work well most of the time.</p> <p>The problem appears when these assumptions are not treated as approximations, but as facts \u2014 and when their effects are allowed to accumulate.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#errors-rarely-come-from-one-place","title":"Errors rarely come from one place","text":"<p>Geospatial systems rarely fail because of a single, large mistake. They fail because many small approximations quietly stack up.</p> <p>Each step in a pixel-to-ground conversion contributes a bit of uncertainty: * the pixel footprint introduces scale ambiguity, * the camera pose introduces angular uncertainty, * altitude introduces vertical uncertainty, * terrain models introduce spatial uncertainty, * reference frames introduce distortion and convention.</p> <p>None of these errors is catastrophic on its own. Together, they consume what engineers call an error budget.</p> <p>When that budget is exhausted, results can still look precise \u2014 but no longer be reliable</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#why-accumulated-errors-are-hard-to-see","title":"Why accumulated errors are hard to see","text":"<p>Stacked errors have an uncomfortable property: they do not announce themselves.</p> <p>They often produce results that are:</p> <ul> <li>smooth,</li> <li>consistent,</li> <li>visually aligned,</li> <li>numerically precise.</li> </ul> <p>Nothing obviously breaks.</p> <p>Instead, the error shows up:</p> <ul> <li>when results are compared across datasets,</li> <li>when relative positions matter,</li> <li>when the same object is observed from different viewpoints,</li> <li>or when outputs are reused outside their original context.</li> </ul> <p>By then, the assumptions that caused the error are long forgotten.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#error-budgets-are-about-intent-not-perfection","title":"Error budgets are about intent, not perfection","text":"<p>Thinking in terms of error budgets does not mean eliminating uncertainty.</p> <p>It means being explicit about:</p> <ul> <li>where precision is required,</li> <li>where approximation is acceptable,</li> <li>and where assumptions are being spent.</li> </ul> <p>A system that acknowledges its error budget can degrade gracefully. A system that ignores it can fail silently.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#when-the-simplification-is-acceptable","title":"When the simplification is acceptable","text":"<p>Not every application needs geometric rigor.</p> <p>In many cases, treating a pixel as a point is a reasonable and conscious tradeoff.</p> <p>This is typically acceptable when:</p> <ul> <li>the goal is visual exploration or qualitative analysis,</li> <li>errors are small relative to the scale of interest,</li> <li>exact positioning has no legal or safety consequences,</li> <li>results are not reused as ground truth.</li> </ul> <p>Examples include:</p> <ul> <li>city discovery or mapping apps,</li> <li>rough tagging or annotation,</li> <li>exploratory data analysis,</li> <li>early-stage prototyping.</li> </ul> <p>In these contexts, simplicity is not a flaw \u2014 it is a feature.</p> <p>The key condition is that the limitation is understood: \u201cThis is approximate, and that\u2019s fine.\u201d</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#and-when-it-is-not","title":"And when it is not","text":"<p>The same simplification becomes problematic when context changes.</p> <p>Treating pixels as points is no longer acceptable when:</p> <ul> <li>relative position matters more than visual alignment,</li> <li>vertical accuracy is critical,</li> <li>results feed into downstream decisions,</li> <li>errors have legal, financial, or safety implications.</li> </ul> <p>Examples include:</p> <ul> <li>infrastructure or asset mapping,</li> <li>land surveying and boundary definition,</li> <li>change detection over time,</li> <li>any workflow where outputs are reused as reference data</li> </ul> <p>In these situations, the cost of a silent assumption can be much higher than the cost of additional complexity : A 1% error on the location of your mailbox relative to your front yard will maybe lead the mailman 10cm away from your mailbox, the same 1% error on a 1 km wide airfield could lead an aircraft with an automated landing system 10 meters outside the runway. Not the same implications and consequences.</p> <p>What matters is not whether the error is large or small, but whether it is controlled.</p>"},{"location":"why-a-pixel-is-not-a-geographic-point/#a-final-distinction-to-keep-in-mind","title":"A final distinction to keep in mind","text":"<p>The difference between an acceptable approximation and a dangerous one is not magnitude.</p> <p>It is awareness.</p> <p>An explicit approximation can be managed, compensated for, or revisited. An implicit one cannot.</p> <p>This is why understanding assumptions \u2014 and how they consume the error budget \u2014 is not an academic concern. It is a practical one.</p> <p>A pixel is not a point. It is a question: \u201cAlong this ray, where do you think the world is?\u201d Pixels have coordinates. Maps have coordinates. But between the two lies geometry \u2014 and choices.</p>"},{"location":"archive/2026/","title":"2026","text":""},{"location":"category/geospatial/","title":"geospatial","text":""}]}